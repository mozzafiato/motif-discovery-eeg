{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tsfresh.feature_extraction import extract_features, EfficientFCParameters\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "utils = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_split(all_sequences, labels, gender_info):\n",
    "\n",
    "    train_sequences = []\n",
    "    validation_sequences = []\n",
    "    train_labels = []\n",
    "    validation_labels = []\n",
    "    train_gender = []\n",
    "    validation_gender = []\n",
    "\n",
    "    for i in [0, 1]:\n",
    "        print(\"Gender:\", i)\n",
    "        gender_ind = list(np.argwhere(gender_info == i).T[0])\n",
    "\n",
    "        all_sequences_ = [sequences for j, sequences in enumerate(all_sequences) if j in gender_ind]\n",
    "        print(len(all_sequences_))\n",
    "        labels_ = [label for j, label in enumerate(labels) if j in gender_ind]\n",
    "        labels_ = np.array(labels_)\n",
    "\n",
    "        split_ratio = 0.15\n",
    "        if i == 1:\n",
    "            split_ratio = 0.3\n",
    "\n",
    "        train_sequences_, validation_sequences_, train_labels_, validation_labels_, train_ind, val_ind = train_test_split(all_sequences_, labels_, gender_ind, stratify=labels_, test_size=split_ratio, random_state=2)\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"--Train:\", len(train_sequences_))\n",
    "        print(\"patient indexes:\", train_ind)\n",
    "        print(\"----\", sum(train_labels_ == 0))\n",
    "        print(\"----\", sum(train_labels_ == 1))\n",
    "        print(\"--Val:\", len(validation_sequences_))\n",
    "        print(\"patient indexes:\", val_ind)\n",
    "        print(\"----\", sum(validation_labels_ == 0))\n",
    "        print(\"----\", sum(validation_labels_ == 1))\n",
    "        \"\"\"\n",
    "\n",
    "        train_sequences.append(train_sequences_)\n",
    "        validation_sequences.append(validation_sequences_)\n",
    "        train_labels.append(list(train_labels_))\n",
    "        validation_labels.append(list(validation_labels_))\n",
    "        train_gender.append([i]*len(train_sequences_))\n",
    "        validation_gender.append([i]*len(validation_sequences_))\n",
    "\n",
    "    # flatten\n",
    "    train_sequences = sum(train_sequences, [])\n",
    "    validation_sequences = sum(validation_sequences, [])\n",
    "    train_labels = np.array(sum(train_labels, []))\n",
    "    validation_labels = np.array(sum(validation_labels, []))\n",
    "    train_gender = sum(train_gender, [])\n",
    "    validation_gender = sum(validation_gender, [])\n",
    "    \n",
    "    return train_sequences, validation_sequences, train_labels, validation_labels, train_gender, validation_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_format(sequences):\n",
    "\n",
    "    # Create a DataFrame with columns: time, value, electrode, patient_id\n",
    "    data = []\n",
    "    for patient_idx, patient_data in enumerate(sequences):  # Iterate over patients\n",
    "        for electrode_idx, electrode_values in enumerate(patient_data):  # Iterate over electrodes\n",
    "            time_indices = range(1, len(electrode_values) + 1)  # Create time indices starting from 1\n",
    "            for time_idx, value in zip(time_indices, electrode_values):  # Iterate over time-value pairs\n",
    "                data.append([patient_idx, electrode_idx, time_idx, value])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"patient_id\", \"electrode\", \"time\", \"value\"])\n",
    "\n",
    "    # Add a unique ID for each patient and electrode combination\n",
    "    df[\"id\"] = df[\"patient_id\"].astype(str) + \"-\" + df[\"electrode\"].astype(str)\n",
    "\n",
    "    print(\"Patient data prepared... \", len(df))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(df, correlation_threshold=0.9, value_threshold=0.9):\n",
    "    # Step 1: Remove features with high correlation\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    to_drop_corr = [column for column in upper_tri.columns if any(upper_tri[column] > correlation_threshold)]\n",
    "    \n",
    "    # Step 2: Remove features with a dominant value (90% or more)\n",
    "    to_drop_value = []\n",
    "    for column in df.columns:\n",
    "        # Check if the most frequent value represents more than `value_threshold` of the data\n",
    "        if df[column].value_counts(normalize=True).iloc[0] >= value_threshold:\n",
    "            to_drop_value.append(column)\n",
    "    \n",
    "    # Combine the features to drop\n",
    "    to_drop = set(to_drop_corr + to_drop_value)\n",
    "    \n",
    "    # Drop the identified features\n",
    "    df_cleaned = df.drop(columns=to_drop)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    # Convert 'electrode' to integer for proper sorting (optional, depending on your data)\n",
    "    df['electrode'] = df.index.str.split(\"-\").str[1].astype(int)\n",
    "    df['patient_id'] = df.index.str.split(\"-\").str[0]\n",
    "\n",
    "    # Now, create a new column name based on the electrode and use it as a suffix\n",
    "    df = df.set_index(['patient_id', 'electrode'])\n",
    "\n",
    "    # Pivot the DataFrame so that each patient has all their electrode features in separate columns\n",
    "    df_pivot = df.unstack(level='electrode')\n",
    "\n",
    "    # Flatten the MultiIndex in columns by concatenating the feature and electrode\n",
    "    df_pivot.columns = [f\"{col[0]}_electrode_{col[1]}\" for col in df_pivot.columns]\n",
    "\n",
    "    # Reset index to bring 'patient_id' back as a column\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "\n",
    "    return df_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tsfresh_features(df, labels, n=None):\n",
    "    # Extract features for all electrodes of all patients\n",
    "    extracted_features = extract_features(\n",
    "        df,\n",
    "        column_id=\"id\",          # Unique identifier (patient + electrode)\n",
    "        column_sort=\"time\",      # Sort by time for time series\n",
    "        column_value=\"value\",    # Observed value column\n",
    "        default_fc_parameters=EfficientFCParameters(),  # Feature extraction parameters\n",
    "        n_jobs=4                 # Parallelization\n",
    "    )\n",
    "\n",
    "    # Expand patient IDs to match electrode IDs\n",
    "    extracted_features[\"patient_id\"] = extracted_features.index.str.split(\"_\").str[0]\n",
    "    print(extracted_features.shape)\n",
    "    print(\"Initial\", extracted_features.columns)\n",
    "\n",
    "    if n != None:\n",
    "        extracted_features = extracted_features.dropna(axis=1)\n",
    "        extracted_features = extracted_features.loc[:, extracted_features.nunique() > 1]\n",
    "\n",
    "        extracted_features_ = remove_highly_correlated_features(extracted_features.drop(\"patient_id\", axis=1))\n",
    "        print(extracted_features_.shape)\n",
    "        remaining_features = list(extracted_features_.columns)\n",
    "        extracted_features_reduced = extracted_features[[*remaining_features, \"patient_id\"]]\n",
    "\n",
    "        aggregated_features = transform_df(extracted_features_reduced)\n",
    "        print(\"Reduced\", aggregated_features.shape)\n",
    "    else:\n",
    "        aggregated_features = transform_df(extracted_features)\n",
    "        print(\"Skipping reducing...\")\n",
    "\n",
    "    aggregated_features['patient_id'] = aggregated_features['patient_id'].astype(int)\n",
    "    aggregated_features = aggregated_features.sort_values(by='patient_id', ascending=True)\n",
    "    aggregated_features = aggregated_features.drop(columns=[\"patient_id\"], errors=\"ignore\")\n",
    "    aggregated_features = aggregated_features.reset_index().drop(\"index\", axis=1)\n",
    "    #print(aggregated_features)\n",
    "\n",
    "    y_series = pd.Series(labels, index=[p for p in range(len(aggregated_features))])\n",
    "\n",
    "    if n != None:\n",
    "        # Compute feature relevance across all patients\n",
    "        relevance_table = calculate_relevance_table(aggregated_features, y_series)\n",
    "\n",
    "        top_features = relevance_table.nsmallest(n, \"p_value\")[\"feature\"]\n",
    "        # Retain only the selected features in the feature matrix\n",
    "        final_features = aggregated_features[top_features]\n",
    "    else:\n",
    "        final_features = aggregated_features\n",
    "        top_features = None\n",
    "\n",
    "\n",
    "    final_features.index = pd.to_numeric(final_features.index)\n",
    "    final_features = final_features.sort_index()\n",
    "\n",
    "    #extracted_features.index = pd.to_numeric(extracted_features.index)\n",
    "    #extracted_features = extracted_features.sort_index()\n",
    "    \n",
    "    return final_features, list(final_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./feature_matrices/'\n",
    "\n",
    "for band in [\"alpha\", \"beta\", \"theta\"]:\n",
    "    print(\"***************************************\")\n",
    "    print(\"***********{}********************\".format(band))\n",
    "    print(\"***************************************\")\n",
    "    \n",
    "    n = None\n",
    "    l = 134\n",
    "\n",
    "    utils.read_data(band=band)\n",
    "    all_sequences = utils.get_all_patient_signals(length=n)[0:l]\n",
    "    labels = np.array(utils.get_labels(labeling=1))[0:l]\n",
    "\n",
    "    test_sequences = utils.get_all_patient_signals(length=n)[l:]\n",
    "    test_labels = utils.get_labels(labeling=1, dataset=\"test\")\n",
    "\n",
    "    all_gender_info = utils.get_gender_info()\n",
    "    gender_info = all_gender_info[:l]\n",
    "    test_gender = all_gender_info[l:]\n",
    "\n",
    "    train_sequences, validation_sequences, train_labels, validation_labels, train_gender, validation_gender = get_balanced_split(all_sequences, labels, gender_info)\n",
    "\n",
    "    # train\n",
    "    df_train = prepare_data_format(train_sequences)\n",
    "    # perform feature selection only in the training dataset\n",
    "    train_feature_matrix, top_features = extract_tsfresh_features(df_train, train_labels, n=80)\n",
    "    train_feature_matrix[\"label\"] = train_labels\n",
    "    print(\"Writing... train feature matrix\")\n",
    "    train_feature_matrix.to_csv(path+\"tsfresh_{}_train.csv\".format(band), index=True)\n",
    "\n",
    "    # val\n",
    "    df_val = prepare_data_format(validation_sequences)\n",
    "    val_feature_matrix, _ = extract_tsfresh_features(df_val, validation_labels, n=None)\n",
    "    val_feature_matrix = val_feature_matrix[top_features]\n",
    "    print(len(list(val_feature_matrix.columns)))\n",
    "\n",
    "    val_feature_matrix[\"label\"] = validation_labels\n",
    "    print(\"Writing... validation feature matrix\")\n",
    "    val_feature_matrix.to_csv(path+\"tsfresh_{}_val.csv\".format(band), index=True)\n",
    "\n",
    "    # test\n",
    "    df_test = prepare_data_format(test_sequences)\n",
    "    test_feature_matrix, _  = extract_tsfresh_features(df_test, test_labels, n=None)\n",
    "    test_feature_matrix = test_feature_matrix[top_features]\n",
    "    print(len(list(test_feature_matrix.columns)))\n",
    "\n",
    "    test_feature_matrix[\"label\"] = test_labels\n",
    "    print(\"Writing... test feature matrix\")\n",
    "    test_feature_matrix.to_csv(path+\"tsfresh_{}_test.csv\".format(band), index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
